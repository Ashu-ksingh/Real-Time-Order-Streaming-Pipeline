# âš¡ Real-Time Order Streaming Data Pipeline

This project demonstrates a complete **real-time data engineering pipeline** using  
**Apache Kafka**, **Spark Structured Streaming**, and **PostgreSQL**.  

It simulates a continuous stream of **e-commerce order events**, processes them with Spark in near real-time, and writes aggregated results to PostgreSQL for analytics.

---

## ğŸ—ï¸ Architecture

Python Producer
â†“
Kafka Topic ("orders")
â†“
Spark Structured Streaming
â†“
PostgreSQL (realtime_customer_sales)

yaml
Copy code

---

## ğŸ§° Tech Stack

- **Python** (Kafka producer + orchestration)
- **Apache Kafka** (message broker)
- **Spark Structured Streaming** (real-time transformations)
- **PostgreSQL** (data storage)
- **Docker Compose** (Kafka + Zookeeper)
- **SQLAlchemy / psycopg2** for DB operations

---

## ğŸ“‚ Project Structure

real_time_order_streaming/
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ producer.py # Kafka producer generating order events
â”‚ â”œâ”€â”€ spark_consumer.py # Spark consumer processing Kafka stream
â”‚ â”œâ”€â”€ main.py # Full pipeline orchestrator
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ db_config.py # PostgreSQL credentials
â”‚ â”œâ”€â”€ kafka_config.py # Kafka topic + broker settings
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ products.json # (optional) static enrichment file
â”‚
â”œâ”€â”€ docker-compose.yml # Kafka + Zookeeper setup
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ§° Setup Instructions and output 

```bash
## 1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

## 2ï¸âƒ£ Start Kafka Environment (Docker)
docker-compose up -d

## 3ï¸âƒ£ Verify Kafka and Zookeeper Containers
docker ps

## 4ï¸âƒ£ Start Kafka Producer (streaming events)
python scripts/producer.py

## 5ï¸âƒ£ Start Spark Structured Streaming Consumer
python scripts/spark_consumer.py

## 6ï¸âƒ£ (Optional) Run Entire Pipeline
python scripts/main.py

## 7ï¸âƒ£ Check Data in PostgreSQL
SELECT * FROM realtime_customer_sales;

## ğŸ—ƒï¸ PostgreSQL Output Table
Table: realtime_customer_sales


Column	Type	Description
window_start	timestamp	Start time of streaming window
window_end	timestamp	End time of streaming window
customer_id	int	Customer identifier
total_sales	double	Total amount spent in window
order_count	int	Number of orders placed

## ğŸ“Š Sample Output
window_start	window_end	customer_id	total_sales	order_count
2025-11-12 22:36:00	2025-11-12 22:37:00	101	2400	3
2025-11-12 22:36:30	2025-11-12 22:37:30	104	1200	1
